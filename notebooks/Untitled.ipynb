{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8c3d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datle/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import math\n",
    "from time import time\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f888f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/datle/.cache/huggingface/datasets/json/default-0913b0ed92067c10/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8f7f075d3c4991ab94aa1b97f6e8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/datle/.cache/huggingface/datasets/json/default-f1b40a908fd17224/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d97b5d5c3c4d9dbcfdf15f86b0425f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_train = \"/Users/datle/Downloads/ELI5.jsonl\"\n",
    "path_val = \"/Users/datle/Downloads/ELI5_val.jsonl\"\n",
    "dataset_train = load_dataset('json', data_files = path_train)\n",
    "dataset_val = load_dataset('json', data_files = path_val)\n",
    "train = dataset_train['train'].select(range(0,1000))\n",
    "val = dataset_val['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c07b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16329d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacetext(string):\n",
    "    return string.replace(\"\\\\\",\"\").replace(\"\\n\",\"\").replace(\"URL_0\",\"\")\n",
    "class eli5dataset(Dataset):\n",
    "    def __init__(self, data, num_docs):\n",
    "        self.data = data\n",
    "        self.qa_id_list = [\n",
    "            (i,j)\n",
    "            for i, qa in enumerate(self.data)\n",
    "            for j, a in enumerate(qa['answers'])\n",
    "        ]\n",
    "        self.num_docs = num_docs\n",
    "    def __len__(self):\n",
    "        return len(self.qa_id_list)\n",
    "    def make_example(self, idx):\n",
    "        i,j = self.qa_id_list[idx]\n",
    "        question = self.data['question'][i]\n",
    "        question = replacetext(question)\n",
    "\n",
    "        context = self.data['ctxs'][i][:self.num_docs]\n",
    "        context = [k[0] for k in context]\n",
    "        context = ' '.join(context)\n",
    "        context = replacetext(context)\n",
    "\n",
    "        answer = self.data['answers'][i][j]\n",
    "\n",
    "        inputs = 'question: {} context: {}'.format(question.lower(), context.lower().strip())\n",
    "\n",
    "        outputs = answer\n",
    "\n",
    "        return (inputs, outputs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.make_example(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a438e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)\n\n",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
