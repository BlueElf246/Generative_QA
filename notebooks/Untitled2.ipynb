{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a81436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datle/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import math\n",
    "from time import time\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101fa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd57bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39000690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bart_model(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "    def forward(self, batch_input):\n",
    "        output = model(**batch_input)\n",
    "        return output.loss, output.logits\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, output = self(batch)\n",
    "        self.log('train_loss',loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, output = self(batch)\n",
    "        self.log('val_loss',loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, output = self(batch)\n",
    "        self.log('test_loss',loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def configure_otimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.0001)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c46ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bart_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef62e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)\n\n",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
