{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-10T18:00:13.293137Z",
     "iopub.status.busy": "2023-07-10T18:00:13.292681Z",
     "iopub.status.idle": "2023-07-10T18:00:25.813634Z",
     "shell.execute_reply": "2023-07-10T18:00:25.812488Z",
     "shell.execute_reply.started": "2023-07-10T18:00:13.293096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:00:25.816720Z",
     "iopub.status.busy": "2023-07-10T18:00:25.816266Z",
     "iopub.status.idle": "2023-07-10T18:00:41.161571Z",
     "shell.execute_reply": "2023-07-10T18:00:41.160594Z",
     "shell.execute_reply.started": "2023-07-10T18:00:25.816680Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import functools\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import math\n",
    "from time import time\n",
    "from datasets import load_dataset, Dataset\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.30.2\n",
      "2.0.1\n",
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:00:41.163687Z",
     "iopub.status.busy": "2023-07-10T18:00:41.162855Z",
     "iopub.status.idle": "2023-07-10T18:03:12.394894Z",
     "shell.execute_reply": "2023-07-10T18:03:12.393827Z",
     "shell.execute_reply.started": "2023-07-10T18:00:41.163648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/datle/.cache/huggingface/datasets/json/default-0913b0ed92067c10/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f508904c7bb4ee58db586672c5d5dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/datle/.cache/huggingface/datasets/json/default-f1b40a908fd17224/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6517a5b6d28e41dda56d968f75d6d046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_train = \"/Users/datle/Downloads/ELI5.jsonl\"\n",
    "path_val = \"/Users/datle/Downloads/ELI5_val.jsonl\"\n",
    "dataset_train = load_dataset('json', data_files = path_train)\n",
    "dataset_val = load_dataset('json', data_files = path_val)\n",
    "train = dataset_train['train'].select(range(1,100))\n",
    "val = dataset_val['train'].select(range(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:03:12.398075Z",
     "iopub.status.busy": "2023-07-10T18:03:12.397636Z",
     "iopub.status.idle": "2023-07-10T18:03:13.134765Z",
     "shell.execute_reply": "2023-07-10T18:03:13.133770Z",
     "shell.execute_reply.started": "2023-07-10T18:03:12.398041Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:03:13.136408Z",
     "iopub.status.busy": "2023-07-10T18:03:13.136062Z",
     "iopub.status.idle": "2023-07-10T18:03:13.146477Z",
     "shell.execute_reply": "2023-07-10T18:03:13.145573Z",
     "shell.execute_reply.started": "2023-07-10T18:03:13.136377Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_text(string):\n",
    "    return string.replace(\"\\'\",\"\").replace(\"\\n\",\"\").replace(\"URL_0\",\"\").lower().strip()\n",
    "def concat(ex, n):\n",
    "    question = replace_text(ex['question'])\n",
    "    context = ex['ctxs'][:n]\n",
    "    if type((context[0])) == list:\n",
    "        context = [k[0] for k in context]\n",
    "    context = replace_text(' '.join(context))\n",
    "    ex['ques_ctxs'] = f\"question: {question} context: {context}\"\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:03:13.148745Z",
     "iopub.status.busy": "2023-07-10T18:03:13.148206Z",
     "iopub.status.idle": "2023-07-10T18:03:24.403358Z",
     "shell.execute_reply": "2023-07-10T18:03:24.402300Z",
     "shell.execute_reply.started": "2023-07-10T18:03:13.148711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/datle/.cache/huggingface/datasets/json/default-0913b0ed92067c10/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-18d0e246eb96737f.arrow\n",
      "Loading cached processed dataset at /Users/datle/.cache/huggingface/datasets/json/default-f1b40a908fd17224/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-367add5173f00b31.arrow\n"
     ]
    }
   ],
   "source": [
    "question_ds_train = train.map(lambda x: concat(x, n=2), remove_columns = ['question', 'ctxs'])\n",
    "question_ds_val = val.map(lambda x: concat(x, n=2), remove_columns = ['question', 'ctxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:03:24.410369Z",
     "iopub.status.busy": "2023-07-10T18:03:24.408080Z",
     "iopub.status.idle": "2023-07-10T18:03:24.421061Z",
     "shell.execute_reply": "2023-07-10T18:03:24.420149Z",
     "shell.execute_reply.started": "2023-07-10T18:03:24.410333Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(ex):\n",
    "    dct = tokenizer(ex['ques_ctxs'],max_length=128, \n",
    "                    padding='max_length', truncation=True, return_tensors='pt')\n",
    "    ex['input_id_q'], ex['attention_q'] = dct['input_ids'][0], dct['attention_mask'][0]\n",
    "    \n",
    "    dct1 = (tokenizer(ex['answers'],max_length=128, \n",
    "                    padding='max_length', truncation=True, return_tensors='pt'))\n",
    "    ex['input_id_a'], ex['attention_a']= dct1['input_ids'], dct1['attention_mask']\n",
    "    \n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:03:24.427644Z",
     "iopub.status.busy": "2023-07-10T18:03:24.425341Z",
     "iopub.status.idle": "2023-07-10T18:07:42.274231Z",
     "shell.execute_reply": "2023-07-10T18:07:42.272836Z",
     "shell.execute_reply.started": "2023-07-10T18:03:24.427610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds_train = question_ds_train.map(tokenize, remove_columns = ['question_id','answers','ques_ctxs'])\n",
    "tokenized_ds_val = question_ds_val.map(tokenize, remove_columns = ['question_id','answers','ques_ctxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_id_q', 'attention_q', 'input_id_a', 'attention_a'],\n",
       "    num_rows: 999\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:36.436712Z",
     "iopub.status.busy": "2023-07-10T18:12:36.435618Z",
     "iopub.status.idle": "2023-07-10T18:12:36.450675Z",
     "shell.execute_reply": "2023-07-10T18:12:36.449434Z",
     "shell.execute_reply.started": "2023-07-10T18:12:36.436674Z"
    }
   },
   "outputs": [],
   "source": [
    "class eli5dataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.qa_id_list = [\n",
    "            (i,j)\n",
    "            for i, q in enumerate(self.dataset['input_id_a'])\n",
    "            for j, a in enumerate(q)\n",
    "        ]\n",
    "    def __len__(self):\n",
    "        return len(self.qa_id_list)\n",
    "    def make_example(self, idx):\n",
    "        q_ids = []\n",
    "        q_mask = []\n",
    "        a_ids = []\n",
    "        a_mask = []\n",
    "        if type(idx) == int:\n",
    "            idx=[idx]\n",
    "        for m in idx:\n",
    "            i,j = self.qa_id_list[m]\n",
    "            \n",
    "        \n",
    "            q_ids.append(self.dataset['input_id_q'][i])\n",
    "            q_mask.append(self.dataset['attention_q'][i])\n",
    "            a_id = self.dataset['input_id_a'][i][j]\n",
    "            a_m = self.dataset['attention_a'][i][j]\n",
    "            a_ids.append(a_id)\n",
    "            a_mask.append(a_m)\n",
    "        \n",
    "        q_ids, q_mask = (\n",
    "        torch.squeeze(torch.LongTensor(q_ids)),\n",
    "        torch.squeeze(torch.LongTensor(q_mask))\n",
    "        )\n",
    "        print('q_ids shape',q_ids.shape)\n",
    "        print('q_mask shape', q_mask.shape)\n",
    "        a_ids, a_mask = (\n",
    "        torch.LongTensor(a_ids),\n",
    "        torch.LongTensor(a_mask)\n",
    "        )\n",
    "        \n",
    "        print('a_ids shape', a_ids.shape)\n",
    "        print('a_mask shape', a_mask.shape)\n",
    "        labels = a_ids[:, 1:].contiguous().clone()\n",
    "        labels[a_mask[:, 1:].contiguous() == 0] = -100\n",
    "        print(\"labels shape\", labels.shape)\n",
    "        model_inputs = {\n",
    "        'input_ids': q_ids,\n",
    "        'attention_mask': q_mask,\n",
    "        'decoder_input_ids': a_ids[:, :-1].contiguous(),\n",
    "        'labels': labels,\n",
    "    }\n",
    "        return model_inputs\n",
    "    def __getitem__(self, idx):\n",
    "        print(idx)\n",
    "        return self.make_example(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:37.483594Z",
     "iopub.status.busy": "2023-07-10T18:12:37.483208Z",
     "iopub.status.idle": "2023-07-10T18:12:37.488653Z",
     "shell.execute_reply": "2023-07-10T18:12:37.487643Z",
     "shell.execute_reply.started": "2023-07-10T18:12:37.483561Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_loader(dataset, args):\n",
    "    train_sampler = SequentialSampler(dataset)\n",
    "#     model_collate_fn = functools.partial(make_qa_s2s_batch,)\n",
    "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:37.834579Z",
     "iopub.status.busy": "2023-07-10T18:12:37.834172Z",
     "iopub.status.idle": "2023-07-10T18:12:37.839772Z",
     "shell.execute_reply": "2023-07-10T18:12:37.838557Z",
     "shell.execute_reply.started": "2023-07-10T18:12:37.834541Z"
    }
   },
   "outputs": [],
   "source": [
    "class ArgumentsS2S():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 2\n",
    "        self.max_length = 128\n",
    "\n",
    "s2s_args = ArgumentsS2S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:38.198670Z",
     "iopub.status.busy": "2023-07-10T18:12:38.198267Z",
     "iopub.status.idle": "2023-07-10T18:12:38.208054Z",
     "shell.execute_reply": "2023-07-10T18:12:38.206844Z",
     "shell.execute_reply.started": "2023-07-10T18:12:38.198639Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "class bart_model(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "    def forward(self, batch_input):\n",
    "        output = self.model(**batch_input)\n",
    "        return output.loss, output.logits\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, output = self(batch)\n",
    "        self.log('train_loss',loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, output = self(batch)\n",
    "        self.log('val_loss',loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, output = self(batch)\n",
    "        self.log('test_loss',loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:38.485275Z",
     "iopub.status.busy": "2023-07-10T18:12:38.484610Z",
     "iopub.status.idle": "2023-07-10T18:12:48.242360Z",
     "shell.execute_reply": "2023-07-10T18:12:48.241300Z",
     "shell.execute_reply.started": "2023-07-10T18:12:38.485240Z"
    }
   },
   "outputs": [],
   "source": [
    "train1 = eli5dataset(tokenized_ds_train)\n",
    "val1 = eli5dataset(tokenized_ds_val)\n",
    "train_1 = data_loader(train1, s2s_args)\n",
    "val_1 = data_loader(val1, s2s_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 40018,    35,   596,    32,   430, 34325,    36, 32786, 28696,\n",
       "           1084, 28696,  4549,    43,     9,  1123,   850,   818,   460,   158,\n",
       "           3205,   430,   116,  5377,    35,    33, 10341,    57,   130,     7,\n",
       "            237,   498,     5,   425,    11,     5, 10409,   982,     6,    19,\n",
       "            850,   148,  3788,  2383, 32857,     9,  4480,   134,     4,   612,\n",
       "             73, 13534,   241,    36,  9006,    68,   134,     4,  3714,   228,\n",
       "           6474,   241,  1358,   245,     4,   306,    73,   687, 50141,  9487,\n",
       "             43,   150,     5,   201,    56,   850,   198,    68,   134,     4,\n",
       "           1096,   228,   201, 17126,  1358,   288,     4,  1749,    73,   462,\n",
       "            322, 10669,    10,   739,   712,   454,     5,  1035,     9,  2266,\n",
       "              6,     5,   253,     9,  2266,  2984,    10,   670,  2991,  3307,\n",
       "             19,    10,  4406,   776, 14013,     6,    19,     5,   674,   425,\n",
       "              9,  2423,    11,     5,   201,    23,    68,     2],\n",
       "         [    0, 40018,    35,   596,    32,   430, 34325,    36, 32786, 28696,\n",
       "           1084, 28696,  4549,    43,     9,  1123,   850,   818,   460,   158,\n",
       "           3205,   430,   116,  5377,    35,    33, 10341,    57,   130,     7,\n",
       "            237,   498,     5,   425,    11,     5, 10409,   982,     6,    19,\n",
       "            850,   148,  3788,  2383, 32857,     9,  4480,   134,     4,   612,\n",
       "             73, 13534,   241,    36,  9006,    68,   134,     4,  3714,   228,\n",
       "           6474,   241,  1358,   245,     4,   306,    73,   687, 50141,  9487,\n",
       "             43,   150,     5,   201,    56,   850,   198,    68,   134,     4,\n",
       "           1096,   228,   201, 17126,  1358,   288,     4,  1749,    73,   462,\n",
       "            322, 10669,    10,   739,   712,   454,     5,  1035,     9,  2266,\n",
       "              6,     5,   253,     9,  2266,  2984,    10,   670,  2991,  3307,\n",
       "             19,    10,  4406,   776, 14013,     6,    19,     5,   674,   425,\n",
       "              9,  2423,    11,     5,   201,    23,    68,     2]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'decoder_input_ids': tensor([[    0,  1620,   951,    54,  2939,  1318, 13252,     6,    38,  2813,\n",
       "             42,    21,  1528,     4,     2,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,   133,  2249,    16,    11,   141,    24, 14827,   600,    16,\n",
       "             99,    18,  2008,    13,    47,    25,     5,   253,  2267,     4,\n",
       "             38,  1305,    10,  1654, 26076,   512,     6,    98,   935,   567,\n",
       "             88,   127,  3819,    16, 34307,   137,    24, 13328,     5, 31108,\n",
       "            147,    24,    18,   617, 34307,    30,     5, 44899,     4,    20,\n",
       "          24306,     6,  4079,     6,     8, 13252,  1123,    32,  5211,    30,\n",
       "          16874,  1728,     6,    61,    11,     5, 28617,  8515,    16,   141,\n",
       "            157,    24, 44430, 32026,     6,  3099,   723, 16874,  1728,  2423,\n",
       "            351,    75, 32768,    31,   239,  1164,    50,  2859,     6,   454,\n",
       "              5,  9049, 10242,  6155,     4,   978,    14,   145,    26,     6,\n",
       "             47,    64,   356,    23,    25,    10,   425, 34348,  1899,     6,\n",
       "             25,    24,    18,    45,   350,   543,     7,   146,   723, 16874,\n",
       "           1728,  1123,     6,    53,  1677,    14,   240]]),\n",
       " 'labels': tensor([[ 1620,   951,    54,  2939,  1318, 13252,     6,    38,  2813,    42,\n",
       "             21,  1528,     4,     2,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "         [  133,  2249,    16,    11,   141,    24, 14827,   600,    16,    99,\n",
       "             18,  2008,    13,    47,    25,     5,   253,  2267,     4,    38,\n",
       "           1305,    10,  1654, 26076,   512,     6,    98,   935,   567,    88,\n",
       "            127,  3819,    16, 34307,   137,    24, 13328,     5, 31108,   147,\n",
       "             24,    18,   617, 34307,    30,     5, 44899,     4,    20, 24306,\n",
       "              6,  4079,     6,     8, 13252,  1123,    32,  5211,    30, 16874,\n",
       "           1728,     6,    61,    11,     5, 28617,  8515,    16,   141,   157,\n",
       "             24, 44430, 32026,     6,  3099,   723, 16874,  1728,  2423,   351,\n",
       "             75, 32768,    31,   239,  1164,    50,  2859,     6,   454,     5,\n",
       "           9049, 10242,  6155,     4,   978,    14,   145,    26,     6,    47,\n",
       "             64,   356,    23,    25,    10,   425, 34348,  1899,     6,    25,\n",
       "             24,    18,    45,   350,   543,     7,   146,   723, 16874,  1728,\n",
       "           1123,     6,    53,  1677,    14,   240,     2]])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:48.244681Z",
     "iopub.status.busy": "2023-07-10T18:12:48.244286Z",
     "iopub.status.idle": "2023-07-10T18:12:51.619840Z",
     "shell.execute_reply": "2023-07-10T18:12:51.618828Z",
     "shell.execute_reply.started": "2023-07-10T18:12:48.244646Z"
    }
   },
   "outputs": [],
   "source": [
    "my_model = bart_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T18:12:51.621844Z",
     "iopub.status.busy": "2023-07-10T18:12:51.621374Z",
     "iopub.status.idle": "2023-07-10T18:13:03.904028Z",
     "shell.execute_reply": "2023-07-10T18:13:03.902468Z",
     "shell.execute_reply.started": "2023-07-10T18:12:51.621807Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 139 M \n",
      "-------------------------------------------------------\n",
      "139 M     Trainable params\n",
      "0         Non-trainable params\n",
      "139 M     Total params\n",
      "557.682   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datle/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n",
      "[2, 3]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datle/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddd41f7cbc445b193ccff0e39bb6e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n",
      "[2, 3]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n",
      "[4, 5]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n",
      "[6, 7]\n",
      "q_ids shape torch.Size([2, 128])\n",
      "q_mask shape torch.Size([2, 128])\n",
      "a_ids shape torch.Size([2, 128])\n",
      "a_mask shape torch.Size([2, 128])\n",
      "labels shape torch.Size([2, 127])\n",
      "[8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datle/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=3)\n",
    "#accelerator='gpu', devices=2\n",
    "trainer.fit(my_model, train_1, val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)\n\n",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
