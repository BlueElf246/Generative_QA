{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightning -q","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:44:55.652244Z","iopub.execute_input":"2023-07-12T03:44:55.652634Z","iopub.status.idle":"2023-07-12T03:45:07.956376Z","shell.execute_reply.started":"2023-07-12T03:44:55.652583Z","shell.execute_reply":"2023-07-12T03:45:07.954981Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\nfrom torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\nimport torch\nimport functools\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport math\nfrom time import time\nfrom datasets import load_dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-12T03:45:07.958825Z","iopub.execute_input":"2023-07-12T03:45:07.959210Z","iopub.status.idle":"2023-07-12T03:45:22.419062Z","shell.execute_reply.started":"2023-07-12T03:45:07.959175Z","shell.execute_reply":"2023-07-12T03:45:22.418009Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"path_train = \"/kaggle/input/eli5-explain-like-i-am-5/ELI5-001.jsonl\"\npath_val = \"/kaggle/input/eli5-explain-like-i-am-5/ELI5_val.jsonl\"\ndataset_train = load_dataset('json', data_files = path_train)\ndataset_val = load_dataset('json', data_files = path_val)\ntrain = dataset_train['train'].select(range(1,30000))\nval = dataset_val['train']","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:45:22.420488Z","iopub.execute_input":"2023-07-12T03:45:22.421705Z","iopub.status.idle":"2023-07-12T03:47:43.106912Z","shell.execute_reply.started":"2023-07-12T03:45:22.421674Z","shell.execute_reply":"2023-07-12T03:47:43.105930Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-d431cd6eeda61f75/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a2e7b97bb234ca7ae42905b885d0fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3eb77d24f6b434aa023330f9585e457"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-d431cd6eeda61f75/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f2f9e14ed3e4928898e5a6e36f2a924"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-6de20c07f97710b3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80cc4a2c264c44bda0a46114e9c2dea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a178f2ae16c4433db283ec443effc140"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6de20c07f97710b3/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931a9d2899594a8792be4953aa377f64"}},"metadata":{}}]},{"cell_type":"code","source":"def replace_text(string):\n    return string.replace(\"\\'\",\"\").replace(\"\\n\",\"\").replace(\"URL_0\",\"\").lower().strip()\ndef preprocess(ex, n):\n    ex['question'] = replace_text(ex['question'])\n#     context = [k[0] for k in ex['ctxs'][:3]]\n#     context = replace_text(' '.join(context))\n    context = ex['ctxs'][:n]\n    if type((context[0])) == list:\n        context = [k[0] for k in context]\n    context = replace_text(' '.join(context))\n    ex['ctxs'] = context\n    ex['answers'] = [replace_text(i) for i in ex['answers']]\n    return ex","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:47:43.114657Z","iopub.execute_input":"2023-07-12T03:47:43.115526Z","iopub.status.idle":"2023-07-12T03:47:43.123138Z","shell.execute_reply.started":"2023-07-12T03:47:43.115494Z","shell.execute_reply":"2023-07-12T03:47:43.122096Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train1 = train.map(lambda ex: preprocess(ex,n=3), remove_columns = ['question_id'])\nval1 = val.map(lambda ex: preprocess(ex,n=3), remove_columns = ['question_id'])","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:47:43.124463Z","iopub.execute_input":"2023-07-12T03:47:43.125389Z","iopub.status.idle":"2023-07-12T03:47:53.826869Z","shell.execute_reply.started":"2023-07-12T03:47:43.125355Z","shell.execute_reply":"2023-07-12T03:47:53.825363Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29999 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addd1714ba0c4b289c4df6a82e92f57c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1507 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918b9384475b439bb9d79df21844765b"}},"metadata":{}}]},{"cell_type":"code","source":"class eli5dataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        self.qa_id_list = [\n            (i,j)\n            for i, qa in enumerate(self.data)\n            for j, a in enumerate(qa['answers'])\n            if j <= 3\n        ]\n    def __len__(self):\n        return len(self.qa_id_list)\n    def make_example(self, idx):\n        i,j = self.qa_id_list[idx]\n        question = self.data['question'][i]\n\n        context = self.data['ctxs'][i]\n\n        answer = self.data['answers'][i][j]\n\n        return (question, context, answer)\n    def __getitem__(self, idx):\n        return self.make_example(idx)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:50:56.335107Z","iopub.execute_input":"2023-07-12T03:50:56.335540Z","iopub.status.idle":"2023-07-12T03:50:56.349859Z","shell.execute_reply.started":"2023-07-12T03:50:56.335507Z","shell.execute_reply":"2023-07-12T03:50:56.348770Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def make_qa_s2s_batch(qa_list, tokenizer, max_len=64, max_a_len=360):\n    q_ls = (q for q, c, a in qa_list)\n    c_ls = (c for q, c, a in qa_list)\n    a_ls = (a for q, c, a in qa_list)\n\n    q_toks = tokenizer.batch_encode_plus(q_ls, c_ls, max_length=max_len, padding='max_length', truncation=True, return_tensors='pt')\n    q_ids, q_mask = (\n        torch.LongTensor(q_toks['input_ids']),\n        torch.LongTensor(q_toks['attention_mask'])\n    )\n    a_toks = tokenizer.batch_encode_plus(a_ls, max_length=min(max_len, max_a_len), padding='max_length', truncation=True,return_tensors='pt')\n    a_ids, a_mask = (\n        torch.LongTensor(a_toks['input_ids']),\n        torch.LongTensor(a_toks['attention_mask'])\n    )\n    labels = a_ids\n    labels[labels == 0] = -100\n    \n#     print('q_ids shape',q_ids.shape)\n#     print('q_mask shape', q_mask.shape)\n#     print('a_ids shape', a_ids.shape)\n#     print('a_mask shape', a_mask.shape)\n#     print(\"labels shape\", labels.shape)\n    \n    model_inputs = {\n        'input_ids': q_ids,\n        'attention_mask': q_mask,\n        'decoder_attention_mask': a_mask,\n        'labels': labels,\n    }\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:50:56.730795Z","iopub.execute_input":"2023-07-12T03:50:56.731245Z","iopub.status.idle":"2023-07-12T03:50:56.747966Z","shell.execute_reply.started":"2023-07-12T03:50:56.731207Z","shell.execute_reply":"2023-07-12T03:50:56.746256Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def data_loader(dataset, args):\n    train_sampler = RandomSampler(dataset)\n    model_collate_fn = functools.partial(make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length)\n    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:50:56.873522Z","iopub.execute_input":"2023-07-12T03:50:56.873897Z","iopub.status.idle":"2023-07-12T03:50:56.880252Z","shell.execute_reply.started":"2023-07-12T03:50:56.873863Z","shell.execute_reply":"2023-07-12T03:50:56.879116Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class ArgumentsS2S():\n    def __init__(self):\n        self.batch_size = 8\n        self.max_length = 256\n\ns2s_args = ArgumentsS2S()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:57:06.516146Z","iopub.execute_input":"2023-07-12T03:57:06.516717Z","iopub.status.idle":"2023-07-12T03:57:06.522430Z","shell.execute_reply.started":"2023-07-12T03:57:06.516675Z","shell.execute_reply":"2023-07-12T03:57:06.521450Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import lightning as L\nclass bart_model(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n    def forward(self, batch_input):\n        output = self.model(**batch_input)\n        return output.loss, output.logits\n    def training_step(self, batch, batch_idx):\n        loss, output = self(batch)\n        self.log('train_loss',loss, prog_bar=True, logger=True)\n        print('train_loss:', loss)\n        return loss\n    def validation_step(self, batch, batch_idx):\n        loss, output = self(batch)\n        self.log('val_loss',loss, prog_bar=True, logger=True)\n        print('val_lss:', loss)\n        return loss\n    def test_step(self, batch, batch_idx):\n        loss, output = self(batch)\n        self.log('test_loss',loss, prog_bar=True, logger=True)\n        return loss\n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(), lr=2e-4)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:59:07.640205Z","iopub.execute_input":"2023-07-12T03:59:07.640661Z","iopub.status.idle":"2023-07-12T03:59:07.662951Z","shell.execute_reply.started":"2023-07-12T03:59:07.640623Z","shell.execute_reply":"2023-07-12T03:59:07.661906Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:57:07.064011Z","iopub.execute_input":"2023-07-12T03:57:07.064395Z","iopub.status.idle":"2023-07-12T03:57:07.168111Z","shell.execute_reply.started":"2023-07-12T03:57:07.064364Z","shell.execute_reply":"2023-07-12T03:57:07.167115Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train2 = eli5dataset(train1)\nval2 = eli5dataset(val1)\ntrain_1 = data_loader(train2, s2s_args)\nval_1 = data_loader(val2, s2s_args)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:57:07.196580Z","iopub.execute_input":"2023-07-12T03:57:07.197246Z","iopub.status.idle":"2023-07-12T03:57:09.621241Z","shell.execute_reply.started":"2023-07-12T03:57:07.197205Z","shell.execute_reply":"2023-07-12T03:57:09.620212Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"my_model = bart_model()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:57:13.430880Z","iopub.execute_input":"2023-07-12T03:57:13.431291Z","iopub.status.idle":"2023-07-12T03:57:16.047553Z","shell.execute_reply.started":"2023-07-12T03:57:13.431253Z","shell.execute_reply":"2023-07-12T03:57:16.046548Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ntrainer = L.Trainer(accelerator='gpu', devices=2, max_epochs=3)\ntrainer.fit(my_model, train_1, val_1)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T03:57:16.050059Z","iopub.execute_input":"2023-07-12T03:57:16.050454Z","iopub.status.idle":"2023-07-12T03:57:48.297434Z","shell.execute_reply.started":"2023-07-12T03:57:16.050419Z","shell.execute_reply":"2023-07-12T03:57:48.294673Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\nINFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nINFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\nINFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\nINFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name  | Type                       | Params\n-----------------------------------------------------\n0 | model | T5ForConditionalGeneration | 222 M \n-----------------------------------------------------\n222 M     Trainable params\n0         Non-trainable params\n222 M     Total params\n891.614   Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n  warning_cache.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1909f061f3d429e931a4256d14a2fa0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\nException ignored in: <function _xla_gc_callback at 0x7d8eeb2fdd80>\nException ignored in: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n<function _xla_gc_callback at 0x7d8eeb2fdd80>\n    Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n    def _xla_gc_callback(*args):def _xla_gc_callback(*args):\nKeyboardInterrupt: \n\nKeyboardInterrupt: \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}